{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7ffb74f4-c06e-47ad-8b22-8f6122c9eb04",
   "metadata": {},
   "source": [
    "# DEFINING AGENT\n",
    "## Software entities that can autononously perform tasks\n",
    "\n",
    "common characteristics of an Agent-\n",
    "- Autonomous\n",
    "- Goal-Oriented\n",
    "- Task specific\n",
    "\n",
    "Designed to work as part of an Agent Framework to solve complex problems with limited human involvement-\n",
    "- Memory/persistence\n",
    "- Decision-making/orchestration\n",
    "- plannig capabilities\n",
    "- Use of tools; potentially connecting to database ot the internet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fafdfa64-94c1-4ab9-9776-8ea231d47e64",
   "metadata": {},
   "source": [
    "## What we are about to do\n",
    "- Image Generation\n",
    "  - Use the OpenAI interface to generate images\n",
    "- Make Agents\n",
    "  - Crate Agents to generate sound and images for our store.\n",
    "- Make an Agent Framework\n",
    "  - Teach our AI Assistant to speak and draw."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a52247d5-58df-4567-bcfd-918d1ffff19b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "\n",
    "# As an alternative, if you'd like to use Ollama instead of OpenAI\n",
    "# Check that Ollama is running for you locally (see week1/day2 exercise) then uncomment these next 2 lines\n",
    "MODEL = \"llama3.2:1b\"\n",
    "openai = OpenAI(base_url='http://localhost:11434/v1', api_key='ollama')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a9979211-15cc-4261-8419-e47ad5710a7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Paradise is a place of perfect peace, happiness, and beauty, often associated with a heavenly or divine location. In many cultures and religious traditions, paradise refers to a state of being that is characterized by extraordinary joy, serenity, and fulfillment.\\n\\nIn a general sense, paradise can refer to any place where one feels completely comfortable, content, and at ease. It's like a warm embrace that wraps around the soul, making everything feel just right. Whether it's a physical location on earth or an idealized concept in the imagination, paradise implies a state of bliss that is often associated with a sense of eternity.\\n\\nIn religious contexts, paradise typically refers to a future state of existence where individuals will be reunited with their loved ones who have passed away, and where they will experience perfect happiness, joy, and divine love. Some example references to paradise include:\\n\\n* The Garden of Eden in the Bible, often seen as a representation of an idealized paradise for humanity.\\n* Heaven or heavenland, which is often associated with religious concepts of a state of eternal bliss.\\n* Paradise Lost, a famous poem by John Milton, describing the fall of man and his eternal torment.\\n\\nIn modern times, the concept of paradise has evolved to include more personal and humanistic interpretations. For example:\\n\\n* A peaceful retreat or vacation where one can relax, recharge, and rejuvenate.\\n* A perfect goal or dream that brings happiness and fulfillment.\\n* A hypothetical place or state that represents the ultimate aspiration for many people.\\n\\nOverall, paradise is a complex and multifaceted concept that can be understood and experienced in diverse ways.\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response= openai.chat.completions.create(\n",
    "    model=MODEL,\n",
    "    messages=[{\"role\":\"system\", \"content\":\"You are a helpful Assistant.\"},\n",
    "             {\"role\":\"user\", \"content\":\"What does paradise mean.\"}]\n",
    ")\n",
    "response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00d745dc-1f25-43b4-93d4-7a366c7b1bcc",
   "metadata": {},
   "source": [
    "## Let's go multi-modal!!\n",
    "We can use DALL-E-3, the image genaration model behind GPT-40, to make us some images.\n",
    "Let's put this in a function called artist."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8670fdbb-b78d-403b-82b7-0e3e9b5f0c90",
   "metadata": {},
   "source": [
    "### Price alert: each time i generate an image it costs about 4c- don't go crazy with images!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a4e83d01-7abd-420b-b8a7-fc88385ad68b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0c79d5a5-42ec-4400-a864-72bb930a20e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialization\n",
    "\n",
    "load_dotenv()\n",
    "os.environ['OPENAI_API_KEY']=os.getenv('OPENAI_API_KEY')\n",
    "MODEL=\"gpt-4o-mini\"\n",
    "openai=OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b50e8954-bcd7-44a8-87dc-834fff0dc250",
   "metadata": {},
   "outputs": [],
   "source": [
    "# some imports for handling images\n",
    "\n",
    "import base64\n",
    "from io import BytesIO\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c325fc3a-8333-4c9c-8b47-504e4c78d0bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def artist(city):\n",
    "    image_response = openai.images.generate(\n",
    "        model=\"dall-e-3\",\n",
    "        prompt=f\"An image representing a vacation in {city}, showing tourist spots and everything unique about {city}, in a vibrant pop-art style\",\n",
    "        size=\"1024x1024\",\n",
    "        n=1,\n",
    "        response_format=\"b64_json\",\n",
    "    )\n",
    "    image_base64=image_response.data[0].b64_json\n",
    "    image_data=base64.b64decode(image_base64)\n",
    "    return Image.open(BytesIO(image_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a04069cc-2744-4dcd-8ae6-dd2310b532b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "image=artist(\"New York City\")\n",
    "display(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6142034b-be27-4cd4-b8af-86e3ab13e027",
   "metadata": {},
   "source": [
    "## AUDIO\n",
    "And let's make a function talker that uses OpenAI's speech model to generate Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4e8ce415-db33-453a-8da0-7057c294a91f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\.conda\\envs\\llms1\\Lib\\site-packages\\pydub\\utils.py:170: RuntimeWarning: Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\n",
      "  warn(\"Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\", RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "from pydub import AudioSegment\n",
    "from pydub.playback import play\n",
    "\n",
    "def talker(message):\n",
    "    response = openai.audio.speech.create(\n",
    "        model=\"tts-1\",\n",
    "        voice=\"onyx\",  # alloy & onyx\n",
    "        input=message\n",
    "    )\n",
    "\n",
    "    audio_stream=BytesIO(response.content)\n",
    "    audio=AudioSegment.from_file(audio_stream, format=\"mp3\")\n",
    "    play(audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f87281ce-5d1b-4645-84b3-6fa49f47f70c",
   "metadata": {},
   "outputs": [],
   "source": [
    "talker(\"Well, hi there\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13a7d00a-6354-4256-a39a-3f6fe45fc728",
   "metadata": {},
   "source": [
    "## Our Agent Framework\n",
    "The term 'Agentic AI' and Agentization is an umbrella term that refers to a number of techniques, such as:\n",
    "\n",
    "- Breaking a complex problem into smaller steps, with multiple LLMs carrying out specialized tasks\n",
    "- The ability for LLMs to use Tools to give them additional capabilities\n",
    "- The 'Agent Environment' which allows Agents to collaborate\n",
    "- An LLM can act as the Planner, dividing bigger tasks into smaller ones for the specialists\n",
    "- The concept of an Agent having autonomy / agency, beyond just responding to a prompt - such as Memory\n",
    "\n",
    "We're showing 1 and 2 here, and to a lesser extent 3 and 5. In week 8 we will do the lot!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3da6aac4-03fe-4dfc-91c2-61553c78e2b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(history):\n",
    "    messages = [{\"role\": \"system\", \"content\": system_message}] + history\n",
    "    response = openai.chat.completions.create(model=MODEL, messages=messages, tools=tools)\n",
    "    image = None\n",
    "    \n",
    "    if response.choices[0].finish_reason==\"tool_calls\":\n",
    "        message = response.choices[0].message\n",
    "        response, city = handle_tool_call(message)\n",
    "        messages.append(message)\n",
    "        messages.append(response)\n",
    "        image = artist(city)\n",
    "        response = openai.chat.completions.create(model=MODEL, messages=messages)\n",
    "        \n",
    "    reply = response.choices[0].message.content\n",
    "    history += [{\"role\":\"assistant\", \"content\":reply}]\n",
    "\n",
    "    # Comment out or delete the next line if you'd rather skip Audio for now..\n",
    "    talker(reply)\n",
    "    \n",
    "    return history, image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ababf57b-1645-48e1-865e-8a00bdb267f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# More involved Gradio code as we're not using the preset Chat interface!\n",
    "# Passing in inbrowser=True in the last line will cause a Gradio window to pop up immediately.\n",
    "\n",
    "with gr.Blocks() as ui:\n",
    "    with gr.Row():\n",
    "        chatbot = gr.Chatbot(height=500, type=\"messages\")\n",
    "        image_output = gr.Image(height=500)\n",
    "    with gr.Row():\n",
    "        entry = gr.Textbox(label=\"Chat with our AI Assistant:\")\n",
    "    with gr.Row():\n",
    "        clear = gr.Button(\"Clear\")\n",
    "\n",
    "    def do_entry(message, history):\n",
    "        history += [{\"role\":\"user\", \"content\":message}]\n",
    "        return \"\", history\n",
    "\n",
    "    entry.submit(do_entry, inputs=[entry, chatbot], outputs=[entry, chatbot]).then(\n",
    "        chat, inputs=chatbot, outputs=[chatbot, image_output]\n",
    "    )\n",
    "    clear.click(lambda: None, inputs=None, outputs=chatbot, queue=False)\n",
    "\n",
    "ui.launch(inbrowser=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4069a0a1-eac1-4a39-ae71-b04ece650ca0",
   "metadata": {},
   "source": [
    "## Exercises and Business Applications\n",
    "- Add in more tools - perhaps to simulate actually booking a flight. A student has done this and provided their example in the community contributions folder.\n",
    "\n",
    "- Next: take this and apply it to your business. Make a multi-modal AI assistant with tools that could carry out an activity for your work. A customer support assistant? New employee onboarding assistant? So many possibilities! Also, see the week2 end of week Exercise in the separate Notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41071413-46cb-4cd5-8834-ab31060079b4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
